# IBM-Learn-Recurrent-Neural-Networks - Personal Work Archive

This repository serves as an archive of my personal work and progress for the **IBM-Learn-Recurrent-Neural-Networks** course. It includes completed activities, notes, and code for each lesson in the course.

## Course Overview

This course explores **Recurrent Neural Networks (RNNs)** and their applications in **Natural Language Processing (NLP)** and **time series analysis**. Topics covered include sequential data, word embeddings, RNNs, and LSTMs.

## Lessons and Progress

Below is a list of the lessons I completed, along with the activities and work I accomplished for each:

1. **Types of Sequential Data**
   - **Notes:** Explored different types of sequential data and their use cases.

2. **Word Embeddings**
   - **Notes:** Learned about word vector representations and their role in NLP tasks.

3. **RNNs (Recurrent Neural Networks)**
   - **Notes:** Studied the architecture and functionality of RNNs, including their strengths and limitations.

4. **LSTMs (Long Short-Term Memory Networks)**
   - **Notes:** Investigated LSTMs as an advanced RNN variant for handling long-term dependencies.


## Purpose of This Repository

This repository is primarily for personal reference and to document my learning journey through the course. It may also serve as a resource for others who are interested in seeing practical examples of the course material.

---

Thank you for visiting! If you have any questions or feedback, feel free to reach out.
